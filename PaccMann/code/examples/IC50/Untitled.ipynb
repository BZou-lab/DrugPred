{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84effbdd-9e25-418e-aa49-1c633726a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from paccmann_predictor.models import MODEL_FACTORY\n",
    "from paccmann_predictor.utils.hyperparams import OPTIMIZER_FACTORY\n",
    "from paccmann_predictor.utils.loss_functions import pearsonr\n",
    "from paccmann_predictor.utils.utils import get_device\n",
    "from pytoda.datasets import DrugSensitivityDataset\n",
    "from pytoda.smiles.smiles_language import SMILESTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "348eff55-63b5-4e75-aaaa-3c553308661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "with open('example_params.json') as fp:\n",
    "    params.update(json.load(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6efa3f00-bcc9-45ca-9bf0-b32cf12b74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('/nas/longleaf/home/qhz/paccmann_predictor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77b00cbf-f48c-4791-b214-281c5247e4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:pytoda.datasets.smiles_dataset:Since you provided a smiles_language, the following parameters to this class will be ignored: canonical, augment, kekulize, all_bonds_explicit, selfies, sanitize, all_hs_explicit, remove_bonddir, remove_chirality, randomize, add_start_and_stop, padding, padding_length, device.\n",
      "Here are the problems:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'canonical'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2730479/1656073362.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_dataset = DrugSensitivityDataset(\n\u001b[0m\u001b[1;32m      2\u001b[0m        \u001b[0mdrug_sensitivity_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_10.csv'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m        \u001b[0msmi_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data/smiles/gdsc.smi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0mgene_expression_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data/gene_expression/gdsc-rnaseq_gene-expression.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0msmiles_language\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'single_pytorch_model/smiles_language'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytoda/datasets/drug_sensitivity_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, drug_sensitivity_filepath, smi_filepath, gene_expression_filepath, column_names, drug_sensitivity_dtype, drug_sensitivity_min_max, drug_sensitivity_processing_parameters, smiles_language, padding, padding_length, add_start_and_stop, augment, canonical, kekulize, all_bonds_explicit, all_hs_explicit, randomize, remove_bonddir, remove_chirality, selfies, sanitize, vocab_file, iterate_dataset, gene_list, gene_expression_standardize, gene_expression_min_max, gene_expression_processing_parameters, gene_expression_dtype, gene_expression_kwargs, device, backend)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# SMILES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         self.smiles_dataset = SMILESTokenizerDataset(\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmi_filepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0msmiles_language\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmiles_language\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytoda/datasets/smiles_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, smiles_language, canonical, augment, kekulize, all_bonds_explicit, all_hs_explicit, remove_bonddir, remove_chirality, selfies, sanitize, randomize, add_start_and_stop, padding, padding_length, device, vocab_file, iterate_dataset, backend, name, *smi_filepaths, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mmismatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'smiles_language.{p.strip()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m                     logger.error(\n\u001b[1;32m    159\u001b[0m                         \u001b[0;34mf'Provided arg {p.strip()}:{eval(p.strip())} does not match the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytoda/datasets/smiles_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'canonical'"
     ]
    }
   ],
   "source": [
    " train_dataset = DrugSensitivityDataset(\n",
    "        drug_sensitivity_filepath='train_10.csv' ,\n",
    "        smi_filepath='data/smiles/gdsc.smi',\n",
    "        gene_expression_filepath='data/gene_expression/gdsc-rnaseq_gene-expression.csv',\n",
    "        smiles_language='single_pytorch_model/smiles_language',\n",
    "        gene_list='data/2128_genes.pkl',\n",
    "        drug_sensitivity_min_max=params.get(\"drug_sensitivity_min_max\", True),\n",
    "        drug_sensitivity_processing_parameters=params.get(\n",
    "            \"drug_sensitivity_processing_parameters\", {}\n",
    "        ),\n",
    "        gene_expression_standardize=params.get(\"gene_expression_standardize\", True),\n",
    "        gene_expression_min_max=params.get(\"gene_expression_min_max\", False),\n",
    "        gene_expression_processing_parameters=params.get(\n",
    "            \"gene_expression_processing_parameters\", {}\n",
    "        ),\n",
    "        device=torch.device(params.get(\"dataset_device\", \"cpu\")),\n",
    "        iterate_dataset=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf28e894-40d1-43d5-9103-999615fd83aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pynvml module not found, please install pynvml\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "print(torch.cuda.list_gpu_processes())\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5393c06f-45eb-4f26-8df0-f1dd0198b3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
